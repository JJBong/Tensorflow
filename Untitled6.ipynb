{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron1 - Initial w1: [ 0.6571136   0.01933569], b1: 0.0103377548148\n",
      "Neuron2 - Initial w2: [ 0.13238403  0.1070995 ], b2: 0.281253732818\n",
      "Neuron2 - Initial w3: [ 0.7923232   0.45396841], b3: 0.563987412663\n",
      "x: [ 0.  0.], z3: 0.699858564192, z_target: 0.0\n",
      "x: [ 1.  0.], z3: 1.28060308492, z_target: 1.0\n",
      "x: [ 0.  1.], z3: 0.763798472658, z_target: 1.0\n",
      "x: [ 1.  1.], z3: 1.34454299338, z_target: 1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Neuron1:\n",
    "    def __init__(self):\n",
    "        self.w1 = np.array([random.random(), random.random()])   # weight of one input\n",
    "        self.b1 = random.random()   # bias\n",
    "        print(\"Neuron1 - Initial w1: {0}, b1: {1}\".format(self.w1, self.b1))\n",
    "\n",
    "    def u1(self, input):\n",
    "        return np.dot(self.w1, input) + self.b1\n",
    "\n",
    "    def f(self, u1):\n",
    "        return max(0.0, u1)\n",
    "\n",
    "    def z1(self, input):\n",
    "        u1 = self.u1(input)\n",
    "        return self.f(u1)\n",
    "\n",
    "class Neuron2:\n",
    "    def __init__(self):\n",
    "        self.w2 = np.array([random.random(), random.random()])   # weight of one input\n",
    "        self.b2 = random.random()   # bias\n",
    "        print(\"Neuron2 - Initial w2: {0}, b2: {1}\".format(self.w2, self.b2))\n",
    "\n",
    "    def u2(self, input):\n",
    "        return np.dot(self.w2, input) + self.b2\n",
    "\n",
    "    def f(self, u2):\n",
    "        return max(0.0, u2)\n",
    "\n",
    "    def z2(self, input):\n",
    "        u2 = self.u2(input)\n",
    "        return self.f(u2)\n",
    "\n",
    "class Neuron3:\n",
    "    def __init__(self, n1, n2):\n",
    "        self.w3 = np.array([random.random(), random.random()])   # weight of one input\n",
    "        self.b3 = random.random()   # bias\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        print(\"Neuron2 - Initial w3: {0}, b3: {1}\".format(self.w3, self.b3))\n",
    "\n",
    "    def u3(self, input):\n",
    "        z1 = self.n1.z1(input)\n",
    "        z2 = self.n2.z2(input)\n",
    "        z = np.array([z1, z2])\n",
    "        return np.dot(self.w3, z) + self.b3\n",
    "\n",
    "    def f(self, u3):\n",
    "        return max(0.0, u3)\n",
    "\n",
    "    def z3(self, input):\n",
    "        u3 = self.u3(input)\n",
    "        return self.f(u3)\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.training_input_value = np.array([(0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 1.0)])\n",
    "        self.training_z_target = np.array([0.0, 1.0, 1.0, 1.0])\n",
    "        self.numTrainData = len(self.training_input_value)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n1 = Neuron1()\n",
    "    n2 = Neuron2()\n",
    "    n3 = Neuron3(n1, n2)\n",
    "    d = Data()\n",
    "    for idx in xrange(d.numTrainData):\n",
    "        input = d.training_input_value[idx]\n",
    "        z3 = n3.z3(input)\n",
    "        z_target = d.training_z_target[idx]\n",
    "        print(\"x: {0}, z3: {1}, z_target: {2}\".format(input, z3, z_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
